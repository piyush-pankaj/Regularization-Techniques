{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1a9dbf",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "Regularization is a technique used to prevent overfitting and improve \n",
    "generalization performance.\n",
    "\n",
    "1. L1 and L2 Regularization\n",
    "2. Dropout\n",
    "3. Data Augmentation\n",
    "4. Early stopping\n",
    "5. Batch Normalization\n",
    "6. Weight Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0607325a",
   "metadata": {},
   "source": [
    "## L1 L2 \n",
    "* L1 regularization: It adds a penalty to the absolute values of the weights in the network.\n",
    "* L2 regularization: It adds a penalty to the square of the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca26448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation = 'relu',kernel_regularizer = regularizers.l1(0.001)),\n",
    "    layers.Dense(10,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7167eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation = 'relu',kernel_regularizer = regularizers.l2(0.001)),\n",
    "    layers.Dense(10,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5148a",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Dropout is a regularization technique that can be used to reduce overfitting in neural network.\n",
    "The idea behind dropout is to randomly drop out(set to zero) some of the neurons in  a layer during training. \n",
    "This forces the remaining neurons to  learn more robust and generalizable feautures, rather than relying on a specific subset of neurons that might only be useful for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d907d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a50f79",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "To implement early stopping, you can monitor the validation loss during training and stop training when the validation loss starts to increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0080da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "monitor = 'val_loss',\n",
    "patience = 3)\n",
    "\n",
    "model.fit(x_train, y_train,epochs = 10, callback = [early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0cf77",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "To implement data augmentation, you can apply various transformations to the training data feeding it into the neural network. Common transformations include random cropping, flipping, and rotaion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f147adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range = 0.2,\n",
    "                                   rotation_range = 20,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True,\n",
    "                                  vertical_flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510fb19",
   "metadata": {},
   "source": [
    "This code sets up an image data generator using the `ImageDataGenerator` class from the Keras library, primarily for data augmentation, which alters images for training neural networks. Here's a brief explanation of each parameter:\n",
    "\n",
    "- `rescale = 1./255`: Scales pixel values to be between 0 and 1 by dividing them by 255.\n",
    "- `shear_range = 0.2`: Applies shearing transformations to the images, distorting them along an axis.\n",
    "- `rotation_range = 20`: Rotates images randomly within the range of -20 to +20 degrees.\n",
    "- `zoom_range = 0.2`: Randomly zooms into images by a factor of up to 20%.\n",
    "- `horizontal_flip = True`: Flips images horizontally (left to right) randomly.\n",
    "- `vertical_flip = True`: Flips images vertically (top to bottom) randomly.\n",
    "\n",
    "These settings enable the generation of variations of the original images, enhancing the diversity of the training data for improved model generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73790815",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "To implement batch normalization, you can add a batch normalization layer after each fully connected ot convolutional layer in  your neural network. The batch normalization layer normalizes the inputs to the layer by subtracting the batch mean and dividing by the batch standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4412a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.BatchNormalization(),   # z = x - m / s\n",
    "    layers.Dense(10,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66907b7",
   "metadata": {},
   "source": [
    "## Weight Constraints\n",
    "In deep learning, weight constraints are a form of regularization that can be used \n",
    "to control the complexity of a neural network by imposing additional contraints \n",
    "on the weights of a network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "110aeaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import constraints\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation = 'relu',kernel_regularizer = regularizers.l2(0.001),\n",
    "                 kernel_constraint = constraints.max_norm(1.)),\n",
    "    layers.Dense(10,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weight = weights * (max_value/ norm(weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
